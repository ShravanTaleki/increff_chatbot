{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6nsv3ibiTN4h",
        "outputId": "04fb6f4c-0b0f-4463-bf8a-e280f883b506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai langchain python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6s_yE_OaTlHE",
        "outputId": "22b646fc-d307-4ec3-aaba-374f9260857b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install transformers if not installed\n",
        "!pip install transformers --quiet\n",
        "\n",
        "import torch\n",
        "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
        "\n",
        "# Force CPU device\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# Model & tokenizer loading\n",
        "model_name = \"facebook/blenderbot-400M-distill\"\n",
        "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
        "model = BlenderbotForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully on CPU!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn1oXX5qUiej",
        "outputId": "7b258b8e-3fef-4a7b-b5a6-be2423897ec0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer loaded successfully on CPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# -----------------------------\n",
        "# 1. FAQ knowledge base\n",
        "# -----------------------------\n",
        "FAQ_KB = {\n",
        "    \"return policy\": \"Our return policy allows you to return any product within 7 days of delivery, provided it is in original condition with packaging.\",\n",
        "    \"track order\": \"You can track your order anytime by logging into your account and visiting the 'Orders' section.\",\n",
        "    \"payment methods\": \"We accept Visa, MasterCard, American Express, PayPal, and Google Pay for your convenience.\",\n",
        "    \"warranty\": \"All our products come with a 1-year manufacturer warranty covering hardware defects.\",\n",
        "    \"specifications\": \"Please specify which product you'd like to know the specifications about — for example, our latest smartphone or laptop.\"\n",
        "}\n",
        "\n",
        "FAQ_KEYWORDS = {\n",
        "    \"return policy\": [\"return\", \"policy\", \"refund\", \"return policy\", \"return policies\"],\n",
        "    \"track order\": [\"track order\", \"where is my order\", \"order status\", \"tracking\"],\n",
        "    \"payment methods\": [\"payment methods\", \"how to pay\", \"payment options\", \"payment\"],\n",
        "    \"warranty\": [\"warranty\", \"guarantee\", \"manufacturer warranty\"],\n",
        "    \"specifications\": [\"specifications\", \"specs\", \"details\", \"product specs\"]\n",
        "}\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Chatbot system prompt\n",
        "# -----------------------------\n",
        "system_prompt = (\n",
        "    \"You are a helpful and professional customer support assistant for an electronics company. \"\n",
        "    \"Your company sells smartphones, laptops, and accessories. \"\n",
        "    \"Always answer politely and concisely with relevant company policies and product information. \"\n",
        "    \"Do not say you are a customer service representative. \"\n",
        "    \"If you do not know the answer, politely say you will find out and get back to the customer.\"\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 3. BlenderBot-based response generator\n",
        "# -----------------------------\n",
        "chat_history = []\n",
        "\n",
        "def generate_blenderbot_response(user_message):\n",
        "    context_lines = chat_history[-4:]\n",
        "    prompt = system_prompt + \"\\n\" + \"\\n\".join(context_lines) + f\"\\nCustomer: {user_message}\\nSupport:\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,       # Pad to longest in batch (only one input here)\n",
        "        max_length=256\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    try:\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_length=60,\n",
        "            pad_token_id=tokenizer.pad_token_id,   # Use tokenizer’s pad_token_id here\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        decoded = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        response = decoded.replace(prompt, \"\").strip()\n",
        "        if not response:\n",
        "            response = \"Hmm, can you clarify that?\"\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(\"----- Detailed error trace -----\")\n",
        "        traceback.print_exc()\n",
        "        print(\"----- End error trace -----\")\n",
        "        return \"Sorry, I encountered an internal error. Please try again.\"\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Main chatbot function\n",
        "# -----------------------------\n",
        "def chat(user_input, history):\n",
        "    user_input_lower = user_input.lower()\n",
        "    for key, keywords in FAQ_KEYWORDS.items():\n",
        "        if any(keyword in user_input_lower for keyword in keywords):\n",
        "            answer = FAQ_KB[key]\n",
        "            chat_history.append(f\"Customer: {user_input}\")\n",
        "            chat_history.append(f\"Support: {answer}\")\n",
        "            return answer\n",
        "\n",
        "    # Else, generate response\n",
        "    chat_history.append(f\"Customer: {user_input}\")\n",
        "    response = generate_blenderbot_response(user_input)\n",
        "    chat_history.append(f\"Support: {response}\")\n",
        "    return response\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Gradio UI\n",
        "# -----------------------------\n",
        "gr.ChatInterface(\n",
        "    fn=chat,\n",
        "    title=\"ElectroAssist – Support Chatbot\",\n",
        "    description=\"Ask anything about your electronic products, orders, payments, or warranty.\",\n",
        "    theme=\"default\",\n",
        ").launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "qbhzu3sxYJaf",
        "outputId": "ff146aa0-f4b6-4ff6-edc0-1e16f66186ff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4412635812a1e7cf08.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4412635812a1e7cf08.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3SIczZAgSaV"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}